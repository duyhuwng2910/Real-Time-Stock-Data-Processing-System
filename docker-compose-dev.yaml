version: "1"

networks:
  kafka-cluster:
    driver: bridge

  spark-cluster:
    driver: bridge

services:
  kafka-controller-1:
    image: confluentinc/cp-server:latest
    hostname: kafka-controller-1
    container_name: kafka-controller-1
    networks:
      - kafka-cluster
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka-controller-1:9092'
      KAFKA_LISTENERS: 'CONTROLLER://kafka-controller-1:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-logs'
      CLUSTER_ID: 'nguyeexnduyhuwng291002'

  kafka-broker-1:
    image: confluentinc/cp-server:latest
    hostname: kafka-broker-1
    container_name: kafka-broker-1
    networks:
      - kafka-cluster
    ports:
      - '9093:9093'
      - '29093:29093'
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'BROKER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka-broker-1:9093,EXTERNAL://localhost:29093'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka-controller-1:9092'
      KAFKA_LISTENERS: 'PLAINTEXT://:9093,EXTERNAL://:29093'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'BROKER'
      KAFKA_LOG_DIRS: '/tmp/kraft-logs'
      CLUSTER_ID: 'nguyeexnduyhuwng291002'

  kafka-broker-2:
    image: confluentinc/cp-server:latest
    hostname: kafka-broker-2
    container_name: kafka-broker-2
    networks:
      - kafka-cluster
    ports:
      - '9094:9094'
      - '29094:29094'
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'BROKER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka-broker-2:9094,EXTERNAL://localhost:29094'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka-controller-1:9092'
      KAFKA_LISTENERS: 'PLAINTEXT://:9094,EXTERNAL://:29094'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'BROKER'
      KAFKA_LOG_DIRS: '/tmp/kraft-logs'
      CLUSTER_ID: 'nguyeexnduyhuwng291002'

  # Dịch vụ Schema Registry
  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    container_name: schema-registry
    networks:
      - kafka-cluster
    ports:
      - "8081:8081"
    depends_on:
      - kafka-controller-1
      - kafka-broker-1
      - kafka-broker-2
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka-broker-1:9093,kafka-broker-2:9094'

  # Dịch vụ Control Center
  control-center:
    image: confluentinc/cp-enterprise-control-center:latest
    container_name: control-center
    networks:
      - kafka-cluster
    ports:
      - "9021:9021"
    depends_on:
      - kafka-controller-1
      - kafka-broker-1
      - kafka-broker-2
      - schema-registry
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka-broker-1:9093,kafka-broker-2:9094'
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1

  # Cấu hình Spark containers
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    networks:
      - spark-cluster
    ports:
      - '8080:8080'
      - '7077:7077'
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    volumes:
      - ./Spark/test_spark_docker.py:/opt/bitnami/spark/test_spark_docker.py
      - ./Spark/test.csv:/opt/bitnami/spark/test.csv
    command: ["bin/spark-class", "org.apache.spark.deploy.master.Master"]

  spark-worker-1:
    image: bitnami/spark:latest
    hostname: spark-worker-1
    networks:
      - spark-cluster
    depends_on:
      - spark-master
    ports:
      - '18080:8080'
      - '7001:7000'
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    command: ["bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]

  spark-worker-2:
    image: bitnami/spark:latest
    hostname: spark-worker-2
    networks:
      - spark-cluster
    depends_on:
      - spark-master
    ports:
      - '28080:8080'
      - '7002:7000'
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    command: ["bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]